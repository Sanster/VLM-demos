# VLM-demos

Collect large multimodal language models that have online demos available.

|Release Date | GitHub|Demo|
|-------------|--------|----|
| 2023.10.05  | [CogVLM](https://github.com/THUDM/CogVLM?tab=readme-ov-file#introduction-to-cogvlm)|  [link](http://36.103.203.44:7861/) |
| 2023.11.06 | [Monkey](https://github.com/Yuliang-Liu/Monkey) | [link](http://27.18.93.119:7681/)|
| 2023.11.28 | [Qwen/Qwen-VL-Plus](https://github.com/QwenLM/Qwen-VL) | [link](https://huggingface.co/spaces/Qwen/Qwen-VL-Plus)|
| 2023.11.28 | [ShareGPT4V](https://github.com/InternLM/InternLM-XComposer/tree/main/projects/ShareGPT4V) | [link](https://huggingface.co/spaces/Lin-Chen/ShareGPT4V-7B) |
| 2023.12.15  | [CogAgent](https://github.com/THUDM/CogVLM?tab=readme-ov-file#introduction-to-cogagent)|  [link](http://36.103.203.44:7861/) |
| 2024.01.18 | [Qwen/Qwen-VL-Max](https://github.com/QwenLM/Qwen-VL) | [link](https://huggingface.co/spaces/Qwen/Qwen-VL-Max) |
| 2024.01.23 | [Vary-toy](https://github.com/Ucas-HaoranWei/Vary-toy)| [link](https://vary.xiaomy.net/) |
| 2024.01.27 | [MoE LLaVA](https://github.com/PKU-YuanGroup/MoE-LLaVA)| [link](https://huggingface.co/spaces/LanguageBind/MoE-LLaVA)|
| 2024.01.30 | [LLaVA-NeXT(llava-v1.6-34b)](https://github.com/haotian-liu/LLaVA) | [link](https://llava.hliu.cc/)|
| 2024.02.07 | [Bunny](https://github.com/BAAI-DCAI/Bunny?tab=readme-ov-file) | [link](https://wisemodel.cn/space/baai/Bunny) |
| 2024.02.18 | [ALLaVA](https://github.com/FreedomIntelligence/ALLaVA?tab=readme-ov-file)  | [link](https://allava.freedomai.cn/#/) |
| 2024.03.06 | [moondream2](https://github.com/vikhyat/moondream) | [link](https://huggingface.co/spaces/vikhyatk/moondream2) |
| 2024.03.07 | [TextMonkey](https://github.com/Yuliang-Liu/Monkey) | [link](http://vlrlab-monkey.xyz:7684/)
